{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Notebook - Machine Learning I"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openml\n",
    "from AdaBoostWorkyWorky import AdaBoost\n",
    "from sklearn.model_selection import KFold, train_test_split, learning_curve\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, roc_curve, roc_auc_score\n",
    "import scipy.stats as ss\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the datasets to use throughout the project\n",
    "\n",
    "Function to read a dataset from [OpenML-CC18 Curated Classification benchmark](https://www.openml.org/search?type=study&sort=tasks_included&study_type=task&id=99) givent its Task ID and return the corresponding Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataset(task_id):\n",
    "    suite = openml.study.get_suite(99)\n",
    "    task = openml.tasks.get_task(task_id)    \n",
    "    dataset = openml.datasets.get_dataset(task.dataset_id)\n",
    "\n",
    "    X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "        dataset_format=\"array\", target=dataset.default_target_attribute\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame(X, columns=attribute_names)\n",
    "    # converter:\n",
    "    #   0 -> -1\n",
    "    #   1 -> 1\n",
    "    df['target'] = 2*y-1 \n",
    "    # erase rows with NaN values\n",
    "    df = df.dropna(how='any', axis=0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of the datasets used in this project:\n",
    "- A\n",
    "- B\n",
    "- C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    (\"Task ID = 15\", getDataset(15)),\n",
    "    (\"Task ID = 24\", getDataset(24)),\n",
    "    (\"Task ID = 3904\", getDataset(3904)),\n",
    "    (\"Task ID = 146820\", getDataset(146820))\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance evaluation of AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to perform cross validation on a set of algorithms (\"algs\")\n",
    "def run_cv(X,y,algs,nfolds=10):\n",
    "    results = {}\n",
    "    kf = KFold(n_splits=nfolds, shuffle=True, random_state=1111)\n",
    "    for algo_name, algo in algs:\n",
    "        results[algo_name] = []\n",
    "        for fold, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "            algo.fit(X_train, y_train)\n",
    "            y_pred = algo.predict(X_test)\n",
    "            results[algo_name].append(accuracy_score(y_test, y_pred))\n",
    "    results_df = pd.DataFrame.from_dict(results)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for dataset wiht Task ID = 15 in 10-fold CV: 0.95322\n",
      "Mean accuracy for dataset wiht Task ID = 24 in 10-fold CV: 0.89795\n",
      "Mean accuracy for dataset wiht Task ID = 3904 in 10-fold CV: 0.80450\n",
      "Mean accuracy for dataset wiht Task ID = 146820 in 10-fold CV: 0.95454\n"
     ]
    }
   ],
   "source": [
    "# running 10-fold cross validation for all datasets and checking accuracy\n",
    "\n",
    "for ds_id, ds in datasets:\n",
    "    X = ds.drop(columns=['target'], axis=1)\n",
    "    y = ds['target']\n",
    "\n",
    "    algs = [(\"AdaBoost\", AdaBoost())]\n",
    "    result = run_cv(X, y, algs)\n",
    "    print(f\"Mean accuracy for dataset wiht {ds_id} in 10-fold CV: {np.mean(result['AdaBoost']):.5f}\")\n",
    "\n",
    "\n",
    "#Mean accuracy for dataset wiht Task ID = 15 in 10-fold CV: 0.96194\n",
    "#Mean accuracy for dataset wiht Task ID = 24 in 10-fold CV: 0.87545\n",
    "#Mean accuracy for dataset wiht Task ID = 3904 in 10-fold CV: 0.80974\n",
    "#Mean accuracy for dataset wiht Task ID = 146820 in 10-fold CV: 0.94606"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot the Confusion Matrix of a fitted model\n",
    "def plot_cm(model_fit,X_test,y_test):\n",
    "    y_pred = model_fit.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix for each dataset\n",
    "for ds_id, ds in datasets:\n",
    "    X = ds.drop(columns=['target'], axis=1)\n",
    "    y = ds['target']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1111)\n",
    "    ab = AdaBoost()\n",
    "    ab.fit(X_train, y_train)\n",
    "    plot_cm(ab, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unable to test ROC Curve because our implementation doesnt have a \"predict_proba\" method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot the Learning Curve of a fitted model\n",
    "def plot_learning_curves(model, X, y, title=''):\n",
    "    training_size = np.linspace(0.1,0.9,10)\n",
    "\n",
    "    train_scores = {}\n",
    "    test_scores = {}\n",
    "    for tr_size in training_size:\n",
    "        train_scores[tr_size] = []\n",
    "        test_scores[tr_size] = []\n",
    "        # run 10 tests with training size = tr_size and store all accuracy results in a line of train_scores and test_scores\n",
    "        for _ in range(10):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=tr_size)\n",
    "            model.fit(X_train, y_train)\n",
    "            training_pred = model.predict(X_train)\n",
    "            testing_pred = model.predict(X_test)\n",
    "            train_scores[tr_size].append(accuracy_score(training_pred, y_train))\n",
    "            test_scores[tr_size].append(accuracy_score(testing_pred, y_test))\n",
    "        # print some statistics\n",
    "        print(\n",
    "            f\"Train size: {tr_size}\\n \\\n",
    "            Mean training score: {round(np.mean(train_scores[tr_size]), 5)}\\n \\\n",
    "            Standard deviation: {round(np.std(train_scores[tr_size]), 5)}\"\n",
    "        )\n",
    "\n",
    "    train_mean = np.array([np.mean(train_scores[tr_size]) for tr_size in training_size])\n",
    "    train_std = np.array([np.std(train_scores[tr_size]) for tr_size in training_size])\n",
    "    test_mean = np.array([np.mean(test_scores[tr_size]) for tr_size in training_size])\n",
    "    test_std = np.array([np.std(test_scores[tr_size]) for tr_size in training_size])\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(training_size, train_mean, 'o-', color='blue', label='Training score')\n",
    "    plt.plot(training_size, test_mean, 'o-', color='green', label='Test score')\n",
    "    plt.fill_between(training_size, train_mean - train_std, train_mean + train_std, alpha=0.1, color='blue')\n",
    "    plt.fill_between(training_size, test_mean - test_std, test_mean + test_std, alpha=0.1, color='green')\n",
    "    plt.xlabel('Training examples')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Learning Curves '+title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Cruve for each dataset\n",
    "for ds_id, ds in datasets:\n",
    "    X = ds.drop(columns=['target'], axis=1)\n",
    "    y = ds['target']\n",
    "\n",
    "    ab = AdaBoost()\n",
    "    plot_learning_curves(ab, X, y, title=\"AdaBoost\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparision of base algorithm and modified ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the models\n",
    "models = [\n",
    "    (\"default\", AdaBoost()),\n",
    "    (\"Alpha 1\", AdaBoost(1)),\n",
    "    (\"Alpha 2\", AdaBoost(2)),\n",
    "    (\"Alpha 3\", AdaBoost(3))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot the results from \n",
    "def plot_cv(results_cv,metric='Accuracy', title=\"Cross-validation results for multiple algorithms in a single task\"):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.boxplot(results_cv)\n",
    "    ax.set_xticklabels(results_cv.columns)\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run 10-fold cross-validation on all algorithms and plot estimates\n",
    "for ds_id, ds in datasets:\n",
    "    X = ds.drop(columns=['target'], axis=1)\n",
    "    y = ds['target']\n",
    "    results = run_cv(X, y, models)\n",
    "    plot_cv(results, title=f\"Cross-validation for the algorithms in the dataset with {ds_id}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    print()\n",
    "    print(i)\n",
    "    X = datasets[i][1].drop(columns=['target'], axis=1)\n",
    "    y = datasets[i][1]['target']\n",
    "    print(\"Tamanho =\", len(y))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    for alg_name, alg in models:\n",
    "        alg.fit(X_train, y_train)\n",
    "        y_pred = alg.predict(X_test)\n",
    "        print(y_pred.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
